{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading images in Tensorflow\n",
    "\n",
    "The recommended way of loading files into Tensorflow is as a TFRecords file.\n",
    "\n",
    "I ripped all of this code from http://machinelearninguru.com/deep_learning/tensorflow/basics/tfrecord/tfrecord.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List images and their labels\n",
    "\n",
    "Load all the images from the dataset directory and generate labels for each one. The dataset is pulled from Kaggle: https://www.kaggle.com/c/dogs-vs-cats\n",
    "\n",
    "Each image is labeled in a separate list and then run through a stable shuffle, then split into 60% training, 20% validation, and 20% testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some setup\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_addrs size: 15000\n",
      "train_labels size: 15000\n",
      "val_addrs size: 5000\n",
      "val_labels size: 5000\n",
      "test_addrs size: 5000\n",
      "test_labels size: 5000\n"
     ]
    }
   ],
   "source": [
    "from random import shuffle\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "\n",
    "shuffle_data = True\n",
    "cat_dog_train_path = \"../Datasets/dogs_and_cats/*.jpg\"\n",
    "\n",
    "# Read addresses and labels from folder\n",
    "addrs = glob.glob(cat_dog_train_path)\n",
    "labels = [0 if \"cat\" in addr else 1 for addr in addrs]\n",
    "\n",
    "# Shuffle data\n",
    "if shuffle_data:\n",
    "    c = list(zip(addrs, labels))\n",
    "    shuffle(c)\n",
    "    addrs, labels = zip(*c)\n",
    "\n",
    "# Divide the data into 60% training, 20% validation, and 20% test\n",
    "train_addrs = addrs[0:int(0.6 * len(addrs))]\n",
    "train_labels = labels[0:int(0.6 * len(labels))]\n",
    "\n",
    "val_addrs = addrs[int(0.6 * len(addrs)):int(0.8 * len(addrs))]\n",
    "val_labels = labels[int(0.6 * len(labels)):int(0.8 * len(labels))]\n",
    "\n",
    "test_addrs = addrs[int(0.8 * len(addrs)):]\n",
    "test_labels = labels[int(0.8 * len(labels)):]\n",
    "\n",
    "print(\"train_addrs size: {}\".format(len(train_addrs)))\n",
    "print(\"train_labels size: {}\".format(len(train_labels)))\n",
    "print(\"val_addrs size: {}\".format(len(val_addrs)))\n",
    "print(\"val_labels size: {}\".format(len(val_labels)))\n",
    "print(\"test_addrs size: {}\".format(len(test_addrs)))\n",
    "print(\"test_labels size: {}\".format(len(test_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert images to a usable format\n",
    "\n",
    "Next we load the images with OpenCV and convert them to a float32, which we'll save to the TFRecords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(addr):\n",
    "    # read an image and resize to (224, 224)\n",
    "    # cv2 load images as BGR, convert it to RGB\n",
    "    img = cv2.imread(addr)\n",
    "    img = cv2.resize(img, (224, 224), interpolation=cv2.INTER_CUBIC)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = img.astype(np.float32)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we put the data into a protocol buffer called `Example`. This protobuf is serialized to a string and written to a TFRecords file. The protobuf contains the protocol `Features`.\n",
    "\n",
    "1) Open a TFRecords file with `tf.python_io.TFRecordWriter`\n",
    "\n",
    "2) Convert data to proper data type\n",
    "\n",
    "3) Create feature using `tf.train.Feature`\n",
    "\n",
    "4) Create protobuf with `tf.train.Example`\n",
    "\n",
    "5) Serialize `Example` to string\n",
    "\n",
    "6) Write out the protobuf to a TFRecords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "# Why can't I use this?\n",
    "def _float32_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: 0/15000\n",
      "train data: 1000/15000\n",
      "train data: 2000/15000\n",
      "train data: 3000/15000\n",
      "train data: 4000/15000\n",
      "train data: 5000/15000\n",
      "train data: 6000/15000\n",
      "train data: 7000/15000\n",
      "train data: 8000/15000\n",
      "train data: 9000/15000\n",
      "train data: 10000/15000\n",
      "train data: 11000/15000\n",
      "train data: 12000/15000\n",
      "train data: 13000/15000\n",
      "train data: 14000/15000\n",
      "val data: 0/5000\n",
      "val data: 1000/5000\n",
      "val data: 2000/5000\n",
      "val data: 3000/5000\n",
      "val data: 4000/5000\n",
      "test data: 0/5000\n",
      "test data: 1000/5000\n",
      "test data: 2000/5000\n",
      "test data: 3000/5000\n",
      "test data: 4000/5000\n"
     ]
    }
   ],
   "source": [
    "# Write out TFRecords files\n",
    "def write_tfrecords(tfr_filename, addrs, labels, feature_name):\n",
    "    \"\"\"\n",
    "    Write TFRecords file to disk from input data.\n",
    "    \n",
    "    Inputs:\n",
    "        tfr_filename: output filename\n",
    "        addrs: input images\n",
    "        labels: input labels\n",
    "        feature_name: train, test, or val.\n",
    "    \"\"\"\n",
    "    writer = tf.python_io.TFRecordWriter(tfr_filename)\n",
    "    for i in range(len(addrs)):\n",
    "        # print how many images are saved every 1000 images\n",
    "        if not i % 1000:\n",
    "            print('{0} data: {1}/{2}'.format(feature_name, i, len(addrs)))\n",
    "            sys.stdout.flush()\n",
    "        # Load the image\n",
    "        img = load_image(addrs[i])\n",
    "        label = labels[i]\n",
    "        # Create a feature\n",
    "        feature = {feature_name + '/label': _int64_feature(label),\n",
    "                   feature_name + '/image': _bytes_feature(tf.compat.as_bytes(img.tostring()))}\n",
    "        # Create an example protocol buffer\n",
    "        example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "        # Serialize to string and write on the file\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "# Write training data\n",
    "write_tfrecords('train.tfrecords', train_addrs, train_labels, 'train')\n",
    "# Write validation data\n",
    "write_tfrecords('val.tfrecords', val_addrs, val_labels, 'val')\n",
    "# Write test data\n",
    "write_tfrecords('test.tfrecords', test_addrs, test_labels, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read TFRecords File\n",
    "\n",
    "Now we read the TFRecords file by loading the training data in batches.\n",
    "\n",
    "- *Create a list of file names* - We just have one training file in this case\n",
    "- *Create a queue to hold filenames* using `tf.train.string_input_producer`. This holds files in a FIFO queue.\n",
    "- *Define a reader* with `tf.TFRecordReader`\n",
    "- *Define a decoder* which decodes the record read by the reader.\n",
    "- *Convert the data from strings back to numbers* using `tf.decode_raw(bytes, out_type)`\n",
    "- *Reshape the data into its original shape* using `tf.reshape`\n",
    "- Then you can do preprocessing and batching as desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Key: train/label.  Data types don't match. Data type: float but expected type: int64\n",
      "\t [[Node: ParseSingleExample/ParseSingleExample = ParseSingleExample[Tdense=[DT_STRING, DT_INT64], dense_keys=[\"train/image\", \"train/label\"], dense_shapes=[[], []], num_sparse=0, sparse_keys=[], sparse_types=[], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](ReaderReadV2:1, ParseSingleExample/Const, ParseSingleExample/Const_1)]]\n",
      "\t [[Node: ParseSingleExample/ParseSingleExample/_23 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_7_ParseSingleExample/ParseSingleExample\", tensor_type=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\nCaused by op 'shuffle_batch', defined at:\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-f57beb35dd20>\", line 23, in <module>\n    images, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 1300, in shuffle_batch\n    name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 846, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 483, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3480, in queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f57beb35dd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mthreads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_queue_runners\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlbl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\nCaused by op 'shuffle_batch', defined at:\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-6-f57beb35dd20>\", line 23, in <module>\n    images, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 1300, in shuffle_batch\n    name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/training/input.py\", line 846, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/data_flow_ops.py\", line 483, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 3480, in queue_dequeue_many_v2\n    component_types=component_types, timeout_ms=timeout_ms, name=name)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/tanmay/miniconda3/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_1_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 10, current size 0)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n"
     ]
    }
   ],
   "source": [
    "data_path = 'train.tfrecords'  # address to save the hdf5 file\n",
    "with tf.Session() as sess:\n",
    "    feature = {'train/image': tf.FixedLenFeature([], tf.string),\n",
    "               'train/label': tf.FixedLenFeature([], tf.int64)}\n",
    "    # Create a list of filenames and pass it to a queue\n",
    "    filename_queue = tf.train.string_input_producer([data_path], num_epochs=1)\n",
    "    # Define a reader and read the next record\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    # Decode the record read by the reader\n",
    "    features = tf.parse_single_example(serialized_example, features=feature)\n",
    "    # Convert the image data from string back to the numbers\n",
    "    image = tf.decode_raw(features['train/image'], tf.float32)\n",
    "    \n",
    "    # Cast label data into int32\n",
    "    label = tf.cast(features['train/label'], tf.int32)\n",
    "    # Reshape image data into the original shape\n",
    "    image = tf.reshape(image, [224, 224, 3])\n",
    "    \n",
    "    # Any preprocessing here ...\n",
    "    \n",
    "    # Creates batches by randomly shuffling tensors\n",
    "    images, labels = tf.train.shuffle_batch([image, label], batch_size=10, capacity=30, num_threads=1, min_after_dequeue=10)\n",
    "    \n",
    "     # Initialize all global and local variables\n",
    "    init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "    sess.run(init_op)\n",
    "    # Create a coordinator and run all QueueRunner objects\n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(coord=coord)\n",
    "    for batch_index in range(5):\n",
    "        img, lbl = sess.run([images, labels])\n",
    "        img = img.astype(np.uint8)\n",
    "        for j in range(6):\n",
    "            plt.subplot(2, 3, j+1)\n",
    "            plt.imshow(img[j, ...])\n",
    "            plt.title('cat' if lbl[j]==0 else 'dog')\n",
    "        plt.show()\n",
    "    # Stop the threads\n",
    "    coord.request_stop()\n",
    "    \n",
    "    # Wait for threads to stop\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*But why do they all say \"cat\"?*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
